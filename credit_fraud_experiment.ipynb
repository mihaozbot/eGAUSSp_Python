{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils.utils_train import train_supervised, train_models_in_threads, test_model_in_batches\n",
    "from utils.utils_plots import plot_first_feature, plot_interesting_features\n",
    "from utils.utils_dataset import balance_dataset, prepare_dataset\n",
    "from utils.utils_dataset import prepare_non_iid_dataset, plot_dataset_split, display_dataset_split\n",
    "from utils.utils_metrics import calculate_metrics, plot_confusion_matrix, calculate_roc_auc\n",
    "#%load_ext line_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.eGauss_plus import eGAUSSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Datasets/creditcard.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select the columns to normalize - all except 'Class'\n",
    "cols_to_normalize = [col for col in data.columns if col != 'Class']\n",
    "\n",
    "# Apply the normalization\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(f\"{torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cpu\") #$torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #torch.device(\"cpu\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    # Creating a 3D scatter plot\\n    fig = go.Figure(data=[go.Scatter3d(\\n        x=results_df['num_sigma'],\\n        y=results_df['kappa_join'],\\n        z=results_df['N_r'],\\n        mode='markers',\\n        marker=dict(\\n            size=5,\\n            color=results_df['f1_score'],  # Set color to the F1 scores\\n            colorscale='Viridis',  # Choose a colorscale\\n            opacity=0.8,\\n            colorbar=dict(title='F1 Score')\\n        )\\n    )])\\n\\n    # Adding labels and title\\n    fig.update_layout(\\n        scene=dict(\\n            xaxis_title='num_sigma',\\n            yaxis_title='kappa_join',\\n            zaxis_title='N_r'\\n        ),\\n        title='F1 Score for Different Parameter Combinations'\\n    )\\n\\n    fig.show()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "\n",
    "if False:\n",
    "\n",
    "    num_clients = 1\n",
    "\n",
    "    # Define the range of values for each parameter\n",
    "    num_sigma_values = [5, 10, 12, 20]\n",
    "    kappa_join_values = [0.3, 0.5, 0.7, 0.8]\n",
    "    N_r_values = [10, 12, 16, 20, 30]\n",
    "\n",
    "    # Total number of experiments\n",
    "    total_experiments = len(num_sigma_values) * len(kappa_join_values) * len(N_r_values)\n",
    "    completed_experiments = 0\n",
    "\n",
    "    # Define other parameters and data setup\n",
    "    local_model_params = {\n",
    "        \"feature_dim\": 30,\n",
    "        \"num_classes\": 2,\n",
    "        \"kappa_n\": 1,\n",
    "        \"S_0\": 1e-10,\n",
    "        \"c_max\": 100,\n",
    "        \"num_samples\": 200, \n",
    "        \"device\": device  # Make sure 'device' is defined\n",
    "    }\n",
    "\n",
    "    # Placeholder for the best parameters and best score\n",
    "    best_params = None\n",
    "    best_score = 0\n",
    "\n",
    "    # List to store all results\n",
    "    results = []\n",
    "\n",
    "    # Iterate over all combinations of parameters\n",
    "    for num_sigma, kappa_join, N_r in itertools.product(num_sigma_values, kappa_join_values, N_r_values):\n",
    "        # Update model parameters\n",
    "        local_model_params.update({\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r})\n",
    "\n",
    "        # Prepare the dataset (assuming prepare_dataset function and data are defined)\n",
    "        X = data.iloc[:, :-1].values\n",
    "        y = data.iloc[:, -1].values\n",
    "        client_train, test_data, all_data = prepare_dataset(X, y, num_clients, balance=10000)\n",
    "\n",
    "        # Train the model on the first client's data and evaluate\n",
    "        local_model = eGAUSSp(**local_model_params)\n",
    "        train_supervised(local_model, client_train[0])  # Train on the first client's data\n",
    "\n",
    "        _, pred_max, _ = test_model_in_batches(local_model, test_data, batch_size= 10)\n",
    "        mertrics = calculate_metrics(pred_max, test_data, weight=\"binary\")\n",
    "        f1_score = mertrics[\"f1_score\"]\n",
    "        # Update best score and parameters if current score is better\n",
    "        if f1_score > best_score:\n",
    "            best_score = f1_score\n",
    "            best_params = {\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r}\n",
    "\n",
    "        # Progress report\n",
    "        completed_experiments += 1\n",
    "        progress = completed_experiments / total_experiments * 100\n",
    "        print(f\"Experiment {completed_experiments}/{total_experiments} ({progress:.2f}%): \"\n",
    "              f\"num_sigma={num_sigma}, kappa_join={kappa_join}, N_r={N_r}, F1 Score: {f1_score}\")\n",
    "\n",
    "        # Store the results\n",
    "        results.append({\n",
    "            \"num_sigma\": num_sigma,\n",
    "            \"kappa_join\": kappa_join,\n",
    "            \"N_r\": N_r,\n",
    "            \"f1_score\": f1_score\n",
    "        })\n",
    "        \n",
    "    # Print the best parameters and the corresponding F1 score\n",
    "    print(f\"Best F1 Score: {best_score}\")\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "'''\n",
    "    # Creating a 3D scatter plot\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=results_df['num_sigma'],\n",
    "        y=results_df['kappa_join'],\n",
    "        z=results_df['N_r'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=results_df['f1_score'],  # Set color to the F1 scores\n",
    "            colorscale='Viridis',  # Choose a colorscale\n",
    "            opacity=0.8,\n",
    "            colorbar=dict(title='F1 Score')\n",
    "        )\n",
    "    )])\n",
    "\n",
    "    # Adding labels and title\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title='num_sigma',\n",
    "            yaxis_title='kappa_join',\n",
    "            zaxis_title='N_r'\n",
    "        ),\n",
    "        title='F1 Score for Different Parameter Combinations'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "local_model_params = {\n",
    "    \"feature_dim\": 30,\n",
    "    \"num_classes\": 2,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 5,\n",
    "    \"kappa_join\": 1,\n",
    "    \"S_0\": 1e-10,\n",
    "    \"N_r\": 8,\n",
    "    \"c_max\": 100,\n",
    "    \"num_samples\": 200,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "federated_model_params = {\n",
    "    \"feature_dim\": 30,\n",
    "    \"num_classes\": 2,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 5,\n",
    "    \"kappa_join\": 1,\n",
    "    \"S_0\": 1e-10,\n",
    "    \"N_r\": 8,\n",
    "    \"c_max\": 100,\n",
    "    \"num_samples\": 200,\n",
    "    \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#display_dataset_split(client_train, test_data)\n",
    "#plot_dataset_split(client_train, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model1, model2):\n",
    "    differences = []\n",
    "\n",
    "    # Function to find differing indices within the overlapping range\n",
    "    def find_differing_indices(tensor1, tensor2):\n",
    "        min_length = min(tensor1.size(0), tensor2.size(0))\n",
    "        differing = (tensor1[:min_length] != tensor2[:min_length]).nonzero(as_tuple=False)\n",
    "        if differing.nelement() == 0:\n",
    "            return \"No differences\"\n",
    "        else:\n",
    "            return differing.view(-1).tolist()  # Flatten and convert to list\n",
    "\n",
    "    # Compare mu parameter and find differing indices\n",
    "    mu_equal = torch.equal(model1.mu[:model1.c], model2.mu[:model2.c])\n",
    "    if not mu_equal:\n",
    "        differing_indices_mu = find_differing_indices(model1.mu[:model1.c], model2.mu[:model2.c])\n",
    "        differences.append(f\"mu parameter differs at indices {differing_indices_mu}\")\n",
    "\n",
    "    # Compare S parameter and find differing indices\n",
    "    S_equal = torch.equal(model1.S[:model1.c], model2.S[:model2.c])\n",
    "    if not S_equal:\n",
    "        differing_indices_S = find_differing_indices(model1.S[:model1.c], model2.S[:model2.c])\n",
    "        differences.append(f\"S parameter differs at indices {differing_indices_S}\")\n",
    "\n",
    "    # Compare n parameter and find differing indices\n",
    "    n_equal = torch.equal(model1.n[:model1.c], model2.n[:model2.c])\n",
    "    if not n_equal:\n",
    "        differing_indices_n = find_differing_indices(model1.n[:model1.c], model2.n[:model2.c])\n",
    "        differences.append(f\"n parameter differs at indices {differing_indices_n}\")\n",
    "\n",
    "    # Check if there are any differences\n",
    "    if differences:\n",
    "        difference_str = \", \".join(differences)\n",
    "        return False, f\"Differences found in: {difference_str}\"\n",
    "    else:\n",
    "        return True, \"Models are identical\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def run_experiment(num_clients, num_rounds, clients_data, test_data):\n",
    "        \n",
    "    # Initialize a model for each client\n",
    "    local_models = [eGAUSSp(**local_model_params) for _ in range(num_clients)]\n",
    "    federated_model = eGAUSSp(**federated_model_params)\n",
    "\n",
    "    # Initialize a list to store the metrics for each round\n",
    "    round_metrics = []\n",
    "\n",
    "    for round in range(num_rounds):\n",
    "        print(f\"--- Communication Round {round + 1} ---\")\n",
    "\n",
    "        aggregated_model = eGAUSSp(**federated_model_params)\n",
    "        federated_model = eGAUSSp(**federated_model_params)\n",
    "\n",
    "        # Train local models\n",
    "        train_models_in_threads(local_models, clients_data)\n",
    "        \n",
    "        '''\n",
    "        for local_model, client_data in zip(local_models, clients_data):\n",
    "             train_supervised(local_model, client_data)\n",
    "\n",
    "             print(f\"Number of local model clusters = {sum(local_model.n[0:local_model.c]> local_model.kappa_n)}\")\n",
    "             all_scores, pred_max, _ = test_model_in_batches(local_model, client_data)\n",
    "             binary = calculate_metrics(pred_max, client_data, \"binary\")\n",
    "             roc_auc = calculate_roc_auc(all_scores, client_data)\n",
    "             print(f\"Test Metrics: {binary}\")\n",
    "             print(f\"Test ROC AUC: {roc_auc}\")\n",
    "             plot_confusion_matrix(pred_max, client_data)\n",
    "        '''   \n",
    "\n",
    "        # Update federated model with local models\n",
    "        for client_idx, client_model in enumerate(local_models):\n",
    "\n",
    "            print(f\"Number of local model clusters = {sum(client_model.n[0:client_model.c]> client_model.kappa_n)}\")\n",
    "            # Run the forward function on the training data\n",
    "            \n",
    "            '''\n",
    "            all_scores, pred_max, _ = test_model_in_batches(client_model, clients_data[client_idx], batch_size=300)\n",
    "            binary = calculate_metrics(pred_max, clients_data[client_idx], \"binary\")\n",
    "            roc_auc = calculate_roc_auc(all_scores, clients_data[client_idx])\n",
    "            print(f\"Test Metrics: {binary}\")\n",
    "            print(f\"Test ROC AUC: {roc_auc}\")\n",
    "            plot_confusion_matrix(pred_max, clients_data[client_idx])\n",
    "            '''\n",
    "\n",
    "            #client_model.federal_agent.federated_merging()\n",
    "            #print(f\"Number of local model clusters after merging = {sum(client_model.n[0:client_model.c]> client_model.kappa_n)}\")\n",
    "\n",
    "            #client_model.federal_agent.federated_merging()\n",
    "            print(f\"Updating agreggated model with client {client_idx + 1}\")\n",
    "\n",
    "            #client_model.federal_agent.federated_merging()\n",
    "            aggregated_model.federal_agent.merge_model_privately(client_model, client_model.kappa_n)\n",
    "            print(f\"Number of agreggated clusters after transfer = {sum(aggregated_model.n[0:aggregated_model.c]> aggregated_model.kappa_n)}\")\n",
    "                \n",
    "        aggregated_model.federal_agent.federated_merging()\n",
    "        print(f\"Number of agreggated clusters after merging = {sum(aggregated_model.n[0:aggregated_model.c]> aggregated_model.kappa_n)}\")\n",
    "\n",
    "                \n",
    "        #client_model.score = 0*client_model.score  \n",
    "        #aggregated_model.S_glo = client_model.S_glo\n",
    "        #aggregated_model.mu_glo = client_model.mu_glo     \n",
    "        \n",
    "        #if round>1:\n",
    "        #    with torch.no_grad():\n",
    "        #        aggregated_model.S = nn.Parameter(aggregated_model.S/2)\n",
    "        #        aggregated_model.n = nn.Parameter(aggregated_model.n/num_clients)\n",
    "\n",
    "        #        aggregated_model.S_glo = aggregated_model.S_glo/2\n",
    "        #        aggregated_model.n_glo = aggregated_model.n_glo/num_clients\n",
    "        \n",
    "\n",
    "        # New code for comparison using the updated compare_models function\n",
    "        #are_models_same, comparison_message = compare_models(client_model, aggregated_model)\n",
    "        #print(f\"Comparison details: {comparison_message}\")\n",
    "\n",
    "        # Update federated model with local models\n",
    "        print(f\"Updating federated model with agreggated model\")\n",
    "        federated_model = aggregated_model #.federal_agent.merge_model_privately(aggregated_model, federated_model.kappa_n)\n",
    "        print(f\"Number of federated clusters after transfer = {sum(federated_model.n[0:federated_model.c]> federated_model.kappa_n)}\")\n",
    "\n",
    "        #local_models = [eGAUSSp(**local_model_params) for _ in range(num_clients)]  \n",
    "        \n",
    "        # Perform federated merging and removal mechanism on the federated model\n",
    "        if any(federated_model.n[0:federated_model.c]> federated_model.kappa_n):\n",
    "\n",
    "            # Evaluate federated model\n",
    "            all_scores_fed, pred_max_fed, _ = test_model_in_batches(federated_model, test_data, batch_size=500)\n",
    "            binary_fed = calculate_metrics(pred_max_fed, test_data, \"binary\")\n",
    "            roc_auc_fed = calculate_roc_auc(all_scores_fed, test_data)\n",
    "            print(f\"Test Metrics: {binary_fed}\")\n",
    "            print(f\"Test ROC AUC: {roc_auc_fed}\")\n",
    "\n",
    "            #plot_confusion_matrix(pred_max_fed, test_data)\n",
    "\n",
    "            # Append metrics to the list\n",
    "            round_metrics.append({\n",
    "                'round': round + 1,\n",
    "                'clusters': federated_model.c,\n",
    "                'binary': binary_fed,\n",
    "                'roc_auc': roc_auc_fed\n",
    "            })\n",
    "\n",
    "        # Return the updated federated model to each client\n",
    "        for client_idx in range(len(local_models)):\n",
    "            print(f\"Returning updated model to client {client_idx + 1}\")\n",
    "            #local_models[client_idx] = federated_model\n",
    "            \n",
    "            local_models[client_idx].federal_agent.merge_model_privately(federated_model, federated_model.kappa_n)\n",
    "            #local_models[client_idx].score = torch.ones_like(local_models[client_idx].score)\n",
    "            #local_models[client_idx].num_pred = torch.zeros_like(local_models[client_idx].score)\n",
    "\n",
    "            #local_models[client_idx].federal_agent.federated_merging()\n",
    "            \n",
    "            '''\n",
    "            # Return the updated federated model to each client\n",
    "            for client_idx, client_model in enumerate(local_models):\n",
    "                print(f\"Returning updated model to client {client_idx + 1}\")\n",
    "                client_model.federal_agent.merge_model_privately(federated_model, federated_model.kappa_n)\n",
    "                client_model.federal_agent.federated_merging()\n",
    "            '''\n",
    "            \n",
    "        print(f\"--- End of Round {round + 1} ---\\n\")\n",
    "        if  round == (num_rounds-1):\n",
    "        #    pass\n",
    "                plot_interesting_features(test_data, model=federated_model, num_sigma=federated_model.num_sigma, N_max = federated_model.kappa_n)   \n",
    "    \n",
    "    # After all rounds\n",
    "    print(\"All Rounds Completed. Metrics Collected:\")\n",
    "    for metric in round_metrics:\n",
    "        print(f\"Round {metric['round']}: Metrics: {metric['binary']}, ROC AUC: {metric['roc_auc']}\")\n",
    "        #print(f\"                         Weighted: {metric['weighted']}\")\n",
    "\n",
    "\n",
    "    return round_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miha\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1: {0: 132, 1: 132}\n",
      "Client 2: {0: 131, 1: 131}\n",
      "Client 3: {0: 131, 1: 131}\n",
      "Test Set: {0: 56864, 1: 98}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 57258 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 57750\n",
      "Running experiment with 3 clients and data configuration 1\n",
      "--- Communication Round 1 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 22\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 10\n",
      "Number of local model clusters = 32\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 21\n",
      "Number of local model clusters = 25\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 30\n",
      "Number of agreggated clusters after merging = 18\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 18\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9821635476282434, 'precision': 0.0661625708884688, 'recall': 0.7142857142857143, 'f1_score': 0.12110726643598614}\n",
      "Test ROC AUC: 0.9734647939085594\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 1 ---\n",
      "\n",
      "--- Communication Round 2 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 141\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 21\n",
      "Number of local model clusters = 148\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 47\n",
      "Number of local model clusters = 163\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 75\n",
      "Number of agreggated clusters after merging = 74\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 74\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9977002212000983, 'precision': 0.38926174496644295, 'recall': 0.5918367346938775, 'f1_score': 0.46963562753036436}\n",
      "Test ROC AUC: 0.971621243812663\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 2 ---\n",
      "\n",
      "--- Communication Round 3 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 169\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 166\n",
      "Number of local model clusters = 172\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 334\n",
      "Number of local model clusters = 188\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 518\n",
      "Number of agreggated clusters after merging = 516\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 516\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9989993328885924, 'precision': 0.8253968253968254, 'recall': 0.5306122448979592, 'f1_score': 0.6459627329192548}\n",
      "Test ROC AUC: 0.971807151039932\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 3 ---\n",
      "\n",
      "--- Communication Round 4 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 197\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 197\n",
      "Number of local model clusters = 197\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 394\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 592\n",
      "Number of agreggated clusters after merging = 592\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 592\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9989817773252344, 'precision': 0.803030303030303, 'recall': 0.5408163265306123, 'f1_score': 0.6463414634146342}\n",
      "Test ROC AUC: 0.9726265963616736\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 4 ---\n",
      "\n",
      "--- Communication Round 5 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 198\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 396\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 594\n",
      "Number of agreggated clusters after merging = 594\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 594\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9989817773252344, 'precision': 0.7777777777777778, 'recall': 0.5714285714285714, 'f1_score': 0.6588235294117646}\n",
      "Test ROC AUC: 0.9813893586415996\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 5 ---\n",
      "\n",
      "--- Communication Round 6 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 197\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 197\n",
      "Number of local model clusters = 197\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 394\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 592\n",
      "Number of agreggated clusters after merging = 592\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 592\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.7866666666666666, 'recall': 0.6020408163265306, 'f1_score': 0.6820809248554913}\n",
      "Test ROC AUC: 0.9815894421921836\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 6 ---\n",
      "\n",
      "--- Communication Round 7 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 198\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 396\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 594\n",
      "Number of agreggated clusters after merging = 594\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 594\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9990168884519505, 'precision': 0.7763157894736842, 'recall': 0.6020408163265306, 'f1_score': 0.6781609195402298}\n",
      "Test ROC AUC: 0.9778006852009233\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 7 ---\n",
      "\n",
      "--- Communication Round 8 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 197\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 197\n",
      "Number of local model clusters = 197\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 394\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 592\n",
      "Number of agreggated clusters after merging = 592\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 592\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9990344440153085, 'precision': 0.7721518987341772, 'recall': 0.6224489795918368, 'f1_score': 0.6892655367231638}\n",
      "Test ROC AUC: 0.9800799329298404\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 8 ---\n",
      "\n",
      "--- Communication Round 9 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 198\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 396\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 594\n",
      "Number of agreggated clusters after merging = 594\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 594\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9989817773252344, 'precision': 0.7439024390243902, 'recall': 0.6224489795918368, 'f1_score': 0.6777777777777778}\n",
      "Test ROC AUC: 0.9796214455112376\n",
      "Returning updated model to client 1\n",
      "Returning updated model to client 2\n",
      "Returning updated model to client 3\n",
      "--- End of Round 9 ---\n",
      "\n",
      "--- Communication Round 10 ---\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Evolving has been disabled.\n",
      "Number of local model clusters = 197\n",
      "Updating agreggated model with client 1\n",
      "Number of agreggated clusters after transfer = 197\n",
      "Number of local model clusters = 197\n",
      "Updating agreggated model with client 2\n",
      "Number of agreggated clusters after transfer = 394\n",
      "Number of local model clusters = 198\n",
      "Updating agreggated model with client 3\n",
      "Number of agreggated clusters after transfer = 592\n",
      "Number of agreggated clusters after merging = 592\n",
      "Updating federated model with agreggated model\n",
      "Number of federated clusters after transfer = 592\n",
      "Evolving has been disabled.\n"
     ]
    }
   ],
   "source": [
    "# List of client counts and data configuration indices\n",
    "client_counts = [3, 10]\n",
    "data_config_indices = [1, 3, 1]  # Replace with your actual data configuration indices\n",
    "\n",
    "# Assuming local_models, client_train, federated_model, and test_data are already defined\n",
    "# Number of communication rounds\n",
    "num_rounds = 100\n",
    "profiler = False\n",
    "experiments = []\n",
    "# Running the experiment\n",
    "for num_clients in client_counts:\n",
    "    for data_config_index in data_config_indices:\n",
    "        if data_config_index == 1:\n",
    "            X = data.iloc[:, :-1].values\n",
    "            y = data.iloc[:, -1].values\n",
    "            client_train, test_data, all_data = prepare_dataset(X, y, num_clients, balance = \"centroids\") \n",
    "            #'random', 'centroids', 'nearmiss', 'enn', 'smote', int num of samples\n",
    "            \n",
    "        if data_config_index == 3:\n",
    "            X = data.iloc[:, :-1].values\n",
    "            y = data.iloc[:, -1].values\n",
    "            client_train, test_data, all_data = prepare_dataset(X, y, num_clients, balance = 'smote') \n",
    "\n",
    "        display_dataset_split(client_train, test_data)\n",
    "        \n",
    "        print(f\"Running experiment with {num_clients} clients and data configuration {data_config_index}\")\n",
    "        if profiler:\n",
    "                        \n",
    "            import cProfile\n",
    "            %load_ext memory_profiler\n",
    "            import yappi\n",
    "\n",
    "            print(f\"... with profiler\")\n",
    "            pr = cProfile.Profile()\n",
    "            pr.enable()\n",
    "            yappi.start()\n",
    "            metrics =  run_experiment(num_clients, num_rounds, client_train, test_data)\n",
    "            yappi.stop()\n",
    "            pr.disable()\n",
    "\n",
    "            pr.print_stats(sort='cumtime')\n",
    "            yappi.get_thread_stats().print_all()\n",
    "            yappi.get_func_stats().print_all()   \n",
    "                   \n",
    "        else:\n",
    "            metrics = run_experiment(num_clients, num_rounds, client_train, test_data)\n",
    "            experiments.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All Rounds Completed. Metrics Collected:\")\n",
    "for metric in metrics:\n",
    "    print(f\"Round {metric['round']}: Metrics: {metric['binary']}, ROC AUC: {metric['roc_auc']}\")\n",
    "    print(f\"                         Weighted: {metric['weighted']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for client_idx, client_model in enumerate(local_models):\n",
    "        print(f\"Merging client {client_idx + 1}\")\n",
    "        #print(f\"Number of client {client_idx + 1} clusters before merging = {torch.sum(client_model.n[:client_model.c]>client_model.kappa_n)}\")\n",
    "        #client_model.federal_agent.federated_merging() \n",
    "        print(f\"Number of client {client_idx + 1} after merging = {torch.sum(client_model.n[:client_model.c]>client_model.kappa_n)}\")\n",
    "        federated_model.federal_agent.merge_model_privately(client_model, client_model.kappa_n)\n",
    "\n",
    "print(f\"Number of clusters after transfer = {federated_model.c}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "federated_model.federal_agent.federated_merging()\n",
    "federated_model.removal_mech.removal_mechanism()\n",
    "print(f\"Number of clusters after merging = {federated_model.c}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "print(f\"\\nTesting federated model\")   \n",
    "\n",
    "all_scores, pred_max, _ = test_model(federated_model, test_data)\n",
    "metrics = calculate_metrics(pred_max, test_data, \"binary\")\n",
    "print(f\"Test Metrics: {metrics}\")\n",
    "roc_auc = calculate_roc_auc(all_scores, test_data)\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "\n",
    "plot_confusion_matrix(pred_max, test_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Confusion matrix values\n",
    "tn = 135\n",
    "fn = 10\n",
    "tp = 132\n",
    "fp = 19\n",
    "\n",
    "# Creating the confusion matrix\n",
    "y_true = [0]*tn + [1]*fn + [1]*tp + [0]*fp  # 0 for negative class, 1 for positive class\n",
    "y_pred = [0]*(tn+fn) + [1]*(fp+tp)  # Predictions\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(accuracy, precision, recall, f1)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
