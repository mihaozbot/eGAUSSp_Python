{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from utils.utils_train import train_supervised, train_models_in_threads, test_model_in_batches\n",
    "from utils.utils_plots import plot_interesting_features, plot_metric_data, save_figure, plot_cluster_data\n",
    "from utils.utils_dataset import balance_dataset, prepare_dataset, balance_data_for_clients\n",
    "from utils.utils_dataset import display_dataset_split\n",
    "from utils.utils_metrics import calculate_metrics, plot_confusion_matrix, calculate_roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.eGauss_plus import eGAUSSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1           58.862440\n",
      "V2           94.773457\n",
      "V3           57.708148\n",
      "V4           22.558515\n",
      "V5          148.544973\n",
      "V6           99.462131\n",
      "V7          164.146736\n",
      "V8           93.223927\n",
      "V9           29.029061\n",
      "V10          48.333399\n",
      "V11          16.816387\n",
      "V12          26.532107\n",
      "V13          12.918764\n",
      "V14          29.741092\n",
      "V15          13.376686\n",
      "V16          31.444966\n",
      "V17          34.416326\n",
      "V18          14.539815\n",
      "V19          12.805499\n",
      "V20          93.918625\n",
      "V21          62.033221\n",
      "V22          21.436234\n",
      "V23          67.336147\n",
      "V24           7.421176\n",
      "V25          17.814986\n",
      "V26           6.121896\n",
      "V27          54.177877\n",
      "V28          49.277892\n",
      "Amount    25691.160000\n",
      "Class         1.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Initialize the StandardScaler\\nscaler = StandardScaler()\\n\\n# Select the columns to normalize - all except 'Class'\\ncols_to_normalize = [col for col in data.columns if col != 'Class']\\n\\n# Apply the normalization\\ndata[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\\n\\n# Set the number of PCA components\\nfeature_dim = 10  # Change this value to adjust the number of components\\n\\n# Initialize PCA\\npca = PCA(n_components=feature_dim)\\n\\n# Apply PCA to the normalized data\\n# Note that we don't apply PCA to the 'Class' column\\npca_data = pca.fit_transform(data[cols_to_normalize])\\n\\n# Create a DataFrame with PCA results and the 'Class' column\\npca_columns = ['PC' + str(i+1) for i in range(feature_dim)]\\npca_data_df = pd.DataFrame(pca_data, columns=pca_columns)\\npca_data_df['Class'] = data['Class']\\n\\ndata = pca_data_df\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Datasets/creditcard.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "feature_dim = 29\n",
    "\n",
    "# Remove the first dimension/column\n",
    "data = data.drop(data.columns[0], axis=1)\n",
    "\n",
    "# Compute the ranges\n",
    "ranges = data.max() - data.min()\n",
    "\n",
    "# Display the ranges\n",
    "print(ranges)\n",
    "\n",
    "'''\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select the columns to normalize - all except 'Class'\n",
    "cols_to_normalize = [col for col in data.columns if col != 'Class']\n",
    "\n",
    "# Apply the normalization\n",
    "data[cols_to_normalize] = scaler.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "# Set the number of PCA components\n",
    "feature_dim = 10  # Change this value to adjust the number of components\n",
    "\n",
    "# Initialize PCA\n",
    "pca = PCA(n_components=feature_dim)\n",
    "\n",
    "# Apply PCA to the normalized data\n",
    "# Note that we don't apply PCA to the 'Class' column\n",
    "pca_data = pca.fit_transform(data[cols_to_normalize])\n",
    "\n",
    "# Create a DataFrame with PCA results and the 'Class' column\n",
    "pca_columns = ['PC' + str(i+1) for i in range(feature_dim)]\n",
    "pca_data_df = pd.DataFrame(pca_data, columns=pca_columns)\n",
    "pca_data_df['Class'] = data['Class']\n",
    "\n",
    "data = pca_data_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(f\"{torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cpu\") #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #torch.device(\"cpu\") #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import threading  # Import the threading module\n",
    "\n",
    "if 0:\n",
    "\n",
    "    num_clients = 1\n",
    "\n",
    "    # Define the range of values for each parameter\n",
    "    num_sigma_values = [5, 10, 15, 20]\n",
    "    kappa_join_values = [0.3, 0.5, 0.8]\n",
    "    N_r_values = [10, 20, 30]\n",
    "\n",
    "    # Total number of experiments\n",
    "    total_experiments = len(num_sigma_values) * len(kappa_join_values) * len(N_r_values)\n",
    "    completed_experiments = 0\n",
    "\n",
    "    # Define other parameters and data setup\n",
    "    local_model_params = {\n",
    "        \"feature_dim\": feature_dim,\n",
    "        \"num_classes\": 2,\n",
    "        \"kappa_n\": 1,\n",
    "        \"S_0\": 1e-10,\n",
    "        \"c_max\": 100,\n",
    "        \"num_samples\": 200, \n",
    "        \"device\": device  # Make sure 'device' is defined\n",
    "    }\n",
    "\n",
    "    # Placeholder for the best parameters and best score\n",
    "    best_params = None\n",
    "    best_score = 0\n",
    "\n",
    "    # List to store all results\n",
    "    results = []\n",
    "\n",
    "    # Function to write data to a file\n",
    "    def write_to_file(file_path, data, mode='a'):\n",
    "        with open(file_path, mode) as file:\n",
    "            file.write(data + \"\\n\")\n",
    "\n",
    "    # Prepare the dataset\n",
    "    # Assuming prepare_dataset function and data are defined\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    client_train_unbalanced, test_data, all_data = prepare_dataset(X, y, num_clients)\n",
    "    client_train = balance_data_for_clients(client_raw_data=client_train_unbalanced, balance=[\"random\"], local_models=None, round=1)\n",
    "    \n",
    "    # Initialize a lock and a shared variable for progress tracking\n",
    "    lock = threading.Lock()\n",
    "    completed_experiments = 0\n",
    "    total_experiments = len(num_sigma_values) * len(kappa_join_values) * len(N_r_values)\n",
    "\n",
    "    # Function to execute model training and evaluation\n",
    "    def train_evaluate_model(params):\n",
    "        global completed_experiments\n",
    "        \n",
    "        num_sigma, kappa_join, N_r = params\n",
    "        local_model_params.update({\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r})\n",
    "\n",
    "        local_model = eGAUSSp(**local_model_params)\n",
    "        train_supervised(local_model, client_train[0])\n",
    "\n",
    "        _, pred_max, _ = test_model_in_batches(local_model, test_data, batch_size = 1000)\n",
    "        metrics = calculate_metrics(pred_max, test_data, weight=\"binary\")\n",
    "\n",
    "        result_str = f\"num_sigma:{num_sigma}, kappa_join:{kappa_join}, N_r:{N_r}, f1_score:{metrics['f1_score']}, precission:{metrics['precision']}, recall:{metrics['recall']}\"\n",
    "        print(result_str)\n",
    "        write_to_file(\"experiment_results.txt\", result_str)  # Write results to file\n",
    "        \n",
    "        # Update progress\n",
    "        with lock:\n",
    "            completed_experiments += 1\n",
    "            progress = (completed_experiments / total_experiments) * 100\n",
    "            print(f\"Progress: {completed_experiments}/{total_experiments} ({progress:.2f}%)\")\n",
    "\n",
    "        return {\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r, \"f1_score\": metrics[\"f1_score\"], \"precission\": metrics[\"precision\"], \"recall\": metrics[\"recall\"]}\n",
    "        \n",
    "\n",
    "    # Write initial setup data to file\n",
    "    initial_setup_str = f\"Initial Setup: num_clients={num_clients}, num_sigma_values={num_sigma_values}, kappa_join_values={kappa_join_values}, N_r_values={N_r_values}\"\n",
    "    write_to_file(\"experiment_results.txt\", initial_setup_str, mode='w')  # 'w' to overwrite if exists\n",
    "\n",
    "    # Using ThreadPoolExecutor to run in multiple threads\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        param_combinations = list(itertools.product(num_sigma_values, kappa_join_values, N_r_values))\n",
    "        results = list(executor.map(train_evaluate_model, param_combinations))\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#display_dataset_split(client_train, test_data)\n",
    "#plot_dataset_split(client_train, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model1, model2):\n",
    "    differences = []\n",
    "\n",
    "    # Function to find differing indices within the overlapping range\n",
    "    def find_differing_indices(tensor1, tensor2):\n",
    "        min_length = min(tensor1.size(0), tensor2.size(0))\n",
    "        differing = (tensor1[:min_length] != tensor2[:min_length]).nonzero(as_tuple=False)\n",
    "        if differing.nelement() == 0:\n",
    "            return \"No differences\"\n",
    "        else:\n",
    "            return differing.view(-1).tolist()  # Flatten and convert to list\n",
    "\n",
    "    # Compare mu parameter and find differing indices\n",
    "    mu_equal = torch.equal(model1.mu[:model1.c], model2.mu[:model2.c])\n",
    "    if not mu_equal:\n",
    "        differing_indices_mu = find_differing_indices(model1.mu[:model1.c], model2.mu[:model2.c])\n",
    "        differences.append(f\"mu parameter differs at indices {differing_indices_mu}\")\n",
    "\n",
    "    # Compare S parameter and find differing indices\n",
    "    S_equal = torch.equal(model1.S[:model1.c], model2.S[:model2.c])\n",
    "    if not S_equal:\n",
    "        differing_indices_S = find_differing_indices(model1.S[:model1.c], model2.S[:model2.c])\n",
    "        differences.append(f\"S parameter differs at indices {differing_indices_S}\")\n",
    "\n",
    "    # Compare n parameter and find differing indices\n",
    "    n_equal = torch.equal(model1.n[:model1.c], model2.n[:model2.c])\n",
    "    if not n_equal:\n",
    "        differing_indices_n = find_differing_indices(model1.n[:model1.c], model2.n[:model2.c])\n",
    "        differences.append(f\"n parameter differs at indices {differing_indices_n}\")\n",
    "\n",
    "    # Check if there are any differences\n",
    "    if differences:\n",
    "        difference_str = \", \".join(differences)\n",
    "        return False, f\"Differences found in: {difference_str}\"\n",
    "    else:\n",
    "        return True, \"Models are identical\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(file_path, data, mode='a'):\n",
    "    with open(file_path, mode) as file:\n",
    "        file.write(data + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_individual_experiment(federated_model_params, local_model_params, num_clients, num_rounds, client_raw_train, test_data, balance, test_clients=True):\n",
    "\n",
    "    local_model_params[\"c_max\"] = int(2*federated_model_params[\"c_max\"]/num_clients)\n",
    "\n",
    "    # Initialize a model for each client\n",
    "    local_models = [eGAUSSp(**local_model_params) for _ in range(num_clients)]\n",
    "    federated_model = eGAUSSp(**federated_model_params)\n",
    "\n",
    "    # Initialize a list to store the metrics for each round\n",
    "    round_metrics = []\n",
    "    result_file = \"experiment_results.txt\"\n",
    "    client_train = []\n",
    "    for round in range(num_rounds):\n",
    "        print(f\"--- Communication Round {round + 1} ---\")\n",
    "        round_info = f\"--- Communication Round {round + 1} ---\\n\"\n",
    "\n",
    "        client_train = balance_data_for_clients(client_raw_data=client_raw_train, balance=balance, local_models=local_models, round=round)\n",
    "        display_dataset_split(client_train, test_data)\n",
    "        \n",
    "        #aggregated_model = eGAUSSp(**federated_model_params)\n",
    "        federated_model = eGAUSSp(**federated_model_params)\n",
    "\n",
    "        # Train local models\n",
    "        train_models_in_threads(local_models, client_train)\n",
    "\n",
    "        '''\n",
    "        for local_model, client_data in zip(local_models, clients_data):\n",
    "             train_supervised(local_model, client_data)\n",
    "\n",
    "             print(f\"Number of local model clusters = {sum(local_model.n[0:local_model.c]> local_model.kappa_n)}\")\n",
    "        '''   \n",
    "\n",
    "        # Update federated model with local models\n",
    "        for client_idx, client_model in enumerate(local_models):\n",
    "\n",
    "            print(f\"Number of local model clusters = {sum(client_model.n[0:client_model.c]> 0)}\")\n",
    "            # Run the forward function on the training data\n",
    "            \n",
    "            if test_clients:\n",
    "                # Calculate and collect metrics for each client model\n",
    "                _, client_pred, _ = test_model_in_batches(client_model, client_train[client_idx], batch_size=500)\n",
    "                client_binary = calculate_metrics(client_pred, client_train[client_idx], \"binary\")\n",
    "                \n",
    "                print(f\"Train Metrics: {client_binary}\")\n",
    "            # plot_confusion_matrix(pred_max, clients_data[client_idx])\n",
    "\n",
    "            print(f\"Updating agreggated model with client {client_idx + 1}\")\n",
    "\n",
    "            federated_model.federal_agent.merge_model_privately(client_model, client_model.kappa_n, pred_min = 0)\n",
    "            \n",
    "        print(f\"Agreggated clusters after transfer = {sum(federated_model.n[0:federated_model.c]> federated_model.kappa_n)}\")\n",
    "\n",
    "        #local_models = [eGAUSSp(**local_model_params) for _ in range(num_clients)] \n",
    "\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Perform federated merging and removal mechanism on the federated model\n",
    "        # Evaluate federated model\n",
    "        agg_clusters = []\n",
    "        agg_binary = []\n",
    "        if test_clients:\n",
    "            agg_scores, agg_pred, _ = test_model_in_batches(federated_model, test_data, batch_size=1000)\n",
    "            agg_binary = calculate_metrics(agg_pred, test_data, \"binary\")\n",
    "            agg_clusters = sum(federated_model.n[0:federated_model.c].cpu() > federated_model.kappa_n)\n",
    "            print(f\"Aggregated Metrics: {agg_binary}\")\n",
    "\n",
    "        federated_model.federal_agent.federated_merging()\n",
    "        print(f\"Federated clusters after merging = {sum(federated_model.n[0:federated_model.c]> federated_model.kappa_n)}\")\n",
    "    \n",
    "        # Evaluate federated model\n",
    "        fed_scores, fed_pred, _ = test_model_in_batches(federated_model, test_data, batch_size=1000)\n",
    "        fed_binary = calculate_metrics(fed_pred, test_data, \"binary\")\n",
    "        fed_roc_auc = calculate_roc_auc(fed_scores, test_data)\n",
    "        print(f\"Test Metrics: {fed_binary}\")\n",
    "        print(f\"Test ROC AUC: {fed_roc_auc}\")\n",
    "        \n",
    "        #plot_confusion_matrix(pred_max_fed, test_data)\n",
    "\n",
    "        print(\"\\n\")\n",
    " \n",
    "        # Return the updated federated model to each client\n",
    "        client_metrics = [] # Reset client metrics for the new round\n",
    "        for client_idx, _ in enumerate(local_models):\n",
    "            print(f\"Returning updated model to client {client_idx + 1}\")\n",
    "\n",
    "            local_models[client_idx].federal_agent.merge_model_privately(federated_model, federated_model.kappa_n, pred_min = 0)\n",
    "            local_models[client_idx].federal_agent.federated_merging()\n",
    "            print(f\"Number of local model clusters after transfer = {sum(local_models[client_idx].n[0:local_models[client_idx].c]> 0)}\")\n",
    "\n",
    "            if test_clients:\n",
    "                # Calculate and collect metrics for each client model\n",
    "                _, client_pred, _ = test_model_in_batches(local_models[client_idx], test_data, batch_size=500)\n",
    "                client_binary = calculate_metrics(client_pred, test_data, \"binary\")\n",
    "\n",
    "                print(f\"Test Metrics client {client_idx} after merge: {client_binary}\")\n",
    "                # plot_confusion_matrix(pred_max, clients_data[client_idx])\n",
    "                \n",
    "                # Calculate additional metrics for each client\n",
    "                client_metrics.append({\n",
    "                    'client_idx': client_idx,\n",
    "                    'binary': client_binary,\n",
    "                    'clusters': sum(local_models[client_idx].n[0:local_models[client_idx].c].cpu()> 0)\n",
    "                })\n",
    "            \n",
    "            #local_models[client_idx].score = torch.ones_like(local_models[client_idx].score)\n",
    "            local_models[client_idx].num_pred = torch.zeros_like(local_models[client_idx].num_pred)\n",
    "            \n",
    "          # Print and write round information to file\n",
    "        round_info = f\"--- End of Round {round + 1} ---\\n\"\n",
    "        print(round_info)\n",
    "        #write_to_file(result_file, round_info)\n",
    "\n",
    "        round_metrics.append({\n",
    "            'round': round + 1,\n",
    "            'federated_model': {\n",
    "                'clusters': sum(federated_model.n[0:federated_model.c].cpu() > federated_model.kappa_n),\n",
    "                'binary': fed_binary,\n",
    "                'roc_auc': fed_roc_auc\n",
    "            },\n",
    "            'aggregated_model': {\n",
    "                'clusters': agg_clusters,\n",
    "                'binary': agg_binary,\n",
    "            },\n",
    "            'client_metrics': client_metrics\n",
    "        })\n",
    "        \n",
    "        \n",
    "        # Plot features for the current round\n",
    "        plt.close('all')  # Close all existing plots to free up memory\n",
    "        if  False:\n",
    "            #fig1 = plot_interesting_features(client_train[0], model=federated_model, num_sigma=federated_model.num_sigma, N_max=federated_model.kappa_n)   \n",
    "            #save_figure(fig1, \"./Images/credit_fraud_clusters\", format='pdf')\n",
    "            fig2 = plot_interesting_features(client_train[0], model=federated_model, num_sigma=2, N_max=federated_model.kappa_n)   \n",
    "            save_figure(fig2, \".Images/credit_fraud_samples.pdf\", format='pdf')\n",
    "\n",
    "        # Iterate over each round's metrics and write to file\n",
    "        for metric in round_metrics:\n",
    "            metric_info = f\"Round {metric['round']}: Metrics: {metric['federated_model']['binary']}, ROC AUC: {metric['federated_model']['roc_auc']}\\n\"\n",
    "            print(metric_info)  # Print each round's metrics\n",
    "            write_to_file(result_file, metric_info)  # Write to file\n",
    "\n",
    "    # After all rounds\n",
    "    final_info = \"All Rounds Completed. Metrics Collected:\\n\"\n",
    "    print(final_info)\n",
    "    #write_to_file(result_file, final_info)\n",
    "\n",
    "    # Iterate over each round's metrics and write to file\n",
    "    for metric in round_metrics:\n",
    "        metric_info = f\"Round {metric['round']}: \"\n",
    "        metric_info += f\"Federated Model - Clusters: {metric['federated_model']['clusters']}, \"\n",
    "        metric_info += f\"Binary Metrics: {metric['federated_model']['binary']}, ROC AUC: {metric['federated_model']['roc_auc']}\\n\"\n",
    "        metric_info += f\"Aggregated Model - Clusters: {metric['aggregated_model']['clusters']}\\n\"\n",
    "\n",
    "        for client_metric in metric['client_metrics']:\n",
    "            metric_info += f\"Client {client_metric['client_idx']} - Binary: {client_metric['binary']}\\n\"\n",
    "\n",
    "        print(metric_info)  # Print each round's metrics\n",
    "        #write_to_file(result_file, metric_info)  # Write to file\n",
    "\n",
    "    return round_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of values for each parameter\n",
    "num_sigma_values = [10, 15, 20]\n",
    "kappa_join_values = [0.3, 0.5, 1]\n",
    "N_r_values = [20, 30]\n",
    "proportion = [1, 5, 10]\n",
    "\n",
    "federated_model_params = {\n",
    "    \"feature_dim\": feature_dim,\n",
    "    \"num_classes\": 2,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 10,\n",
    "    \"kappa_join\": 0.8,\n",
    "    \"S_0\": 1e-10,\n",
    "    \"N_r\": 30,\n",
    "    \"c_max\": 300, #local_model_params[\"c_max\"]*num_clients,\n",
    "    \"num_samples\": 1000,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "    # Model parameters\n",
    "local_model_params = {\n",
    "    \"feature_dim\": feature_dim,\n",
    "    \"num_classes\": 2,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 10,\n",
    "    \"kappa_join\": 0.8,\n",
    "    \"S_0\": 1e-10,\n",
    "    \"N_r\": 30,\n",
    "    \"c_max\": 0,\n",
    "    \"num_samples\": 1000,\n",
    "    \"device\": device\n",
    "}\n",
    "\n",
    "# List of client counts and data configuration indices\n",
    "client_counts = [3]\n",
    "data_config_indices = [1]  # Replace with your actual data configuration indices\n",
    "\n",
    "# Assuming local_models, client_train, federated_model, and test_data are already defined\n",
    "# Number of communication rounds\n",
    "num_rounds = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_experiments(data, client_counts, data_config_indices, federated_model_params, local_model_params, num_rounds, proportion=1, profiler=False):\n",
    "    experiments = []\n",
    "    results_dir = \".Results\"  # Directory to save the results\n",
    "    os.makedirs(results_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "    for num_clients in client_counts:\n",
    "        for data_config_index in data_config_indices:\n",
    "            X = data.iloc[:, :-1].values\n",
    "            y = data.iloc[:, -1].values\n",
    "            client_raw_train, test_data, all_data = prepare_dataset(X, y, num_clients)\n",
    "\n",
    "            balance = None\n",
    "            if data_config_index == 1:\n",
    "                balance = ['random'] * int(proportion)\n",
    "            elif data_config_index == 2:\n",
    "                balance = 'Smote'\n",
    "\n",
    "            print(f\"Running experiment with {num_clients} clients and data configuration {data_config_index}\")\n",
    "            \n",
    "            if profiler:\n",
    "                # Import profiling packages only if profiler is True\n",
    "                import cProfile\n",
    "                import yappi\n",
    "                try:\n",
    "                    # Try to load the memory_profiler extension if it's available\n",
    "                    get_ipython().run_line_magic('load_ext', 'memory_profiler')\n",
    "                except:\n",
    "                    print(\"Memory profiler not available.\")\n",
    "\n",
    "                print(f\"... with profiler\")\n",
    "                pr = cProfile.Profile()\n",
    "                pr.enable()\n",
    "                yappi.start()\n",
    "                \n",
    "                metrics = run_individual_experiment(federated_model_params=federated_model_params, \n",
    "                                                    local_model_params=local_model_params, \n",
    "                                                    num_clients=num_clients, num_rounds=num_rounds, \n",
    "                                                    client_raw_train=client_raw_train, test_data=test_data,\n",
    "                                                    balance=balance, test_clients=True)\n",
    "                yappi.stop()\n",
    "                pr.disable()\n",
    "\n",
    "                pr.print_stats(sort='cumtime')\n",
    "                yappi.get_thread_stats().print_all()\n",
    "                yappi.get_func_stats().print_all()\n",
    "            else:\n",
    "                metrics = run_individual_experiment(federated_model_params=federated_model_params, \n",
    "                                                    local_model_params=local_model_params, \n",
    "                                                    num_clients=num_clients, num_rounds=num_rounds, \n",
    "                                                    client_raw_train=client_raw_train, test_data=test_data,\n",
    "                                                    balance=balance, test_clients=True)\n",
    "\n",
    "            experiments.append((f\"num_clients_{num_clients}_sampling_{data_config_index}\", metrics))\n",
    "\n",
    "    # Construct a specific name for the saved file\n",
    "    file_name = f'experiment_metrics_num_clients_{max(client_counts)}_config_{max(data_config_indices)}_rounds_{num_rounds}.pth'\n",
    "    file_path = os.path.join(results_dir, file_name)\n",
    "\n",
    "    # Save the experiments\n",
    "    torch.save(experiments, file_path)\n",
    "    print(f\"Saved experiments to {file_path}\")\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_metric(experiments, round_number=5):\n",
    "    # Assuming the experiments list contains the metrics for each experiment\n",
    "    # and each experiment's metrics contain the F1 score for the federated model\n",
    "    for experiment in experiments:\n",
    "        if experiment['round'] == round_number:\n",
    "            # Assuming 'binary' key contains a dictionary where 'f1_score' is one of the keys\n",
    "            return experiment['federated_model']['binary']['f1_score']\n",
    "    return None\n",
    "\n",
    "def run_parameterized_experiments(data, client_counts, data_config_indices, num_rounds, profiler=False):\n",
    "    best_setting = None\n",
    "    best_f1_score = -float('inf')\n",
    "    all_experiments_metrics = []\n",
    "\n",
    "    for num_sigma in num_sigma_values:\n",
    "        for kappa_join in kappa_join_values:\n",
    "            for N_r in N_r_values:\n",
    "                for prop in proportion:\n",
    "                    # Update the model parameters\n",
    "                    federated_model_params.update({\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r})\n",
    "                    local_model_params.update({\"num_sigma\": num_sigma, \"kappa_join\": kappa_join, \"N_r\": N_r})\n",
    "\n",
    "                    # Run the experiment\n",
    "                    experiments = run_experiments(data, client_counts, data_config_indices, federated_model_params, local_model_params, num_rounds, prop, profiler)\n",
    "\n",
    "                    # Store all experiments' metrics\n",
    "                    all_experiments_metrics.append(experiments)\n",
    "\n",
    "                    # Evaluate the F1 score of the 5th round\n",
    "                    f1_score = evaluate_metric(experiments, round_number=5)\n",
    "                    \n",
    "                    # Update the best setting if current setting's F1 score is better\n",
    "                    if f1_score and f1_score > best_f1_score:\n",
    "                        best_f1_score = f1_score\n",
    "                        best_setting = (num_sigma, kappa_join, N_r, prop)\n",
    "\n",
    "    return best_setting, best_f1_score, all_experiments_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with 3 clients and data configuration 1\n",
      "--- Communication Round 1 ---\n",
      "Client 1: {0: 132, 1: 132}\n",
      "Client 2: {0: 131, 1: 131}\n",
      "Client 3: {0: 131, 1: 131}\n",
      "Test Set: {0: 56864, 1: 98}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 57258 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 57750\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Number of local model clusters = 216\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 1\n",
      "Updated var_glo values: tensor(26.1409)\n",
      "Number of local model clusters = 209\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 2\n",
      "Updated var_glo values: tensor(27.2257)\n",
      "Number of local model clusters = 235\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 3\n",
      "Updated var_glo values: tensor(28.0701)\n",
      "Agreggated clusters after transfer = 91\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Aggregated Metrics: {'accuracy': 0.9378181945858642, 'precision': 0.022197558268590455, 'recall': 0.8163265306122449, 'f1_score': 0.04321988114532685}\n",
      "Federated clusters after merging = 63\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9828833257259225, 'precision': 0.0721951219512195, 'recall': 0.7551020408163265, 'f1_score': 0.13178984861976847}\n",
      "Test ROC AUC: 0.9502393106933263\n",
      "\n",
      "\n",
      "Returning updated model to client 1\n",
      "Updated var_glo values: tensor(27.5868)\n",
      "Number of local model clusters after transfer = 236\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 0 after merge: {'accuracy': 0.9477546434465082, 'precision': 0.02757715036112935, 'recall': 0.8571428571428571, 'f1_score': 0.05343511450381679}\n",
      "Returning updated model to client 2\n",
      "Updated var_glo values: tensor(28.1305)\n",
      "Number of local model clusters after transfer = 222\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 1 after merge: {'accuracy': 0.955110424493522, 'precision': 0.032331685051350326, 'recall': 0.8673469387755102, 'f1_score': 0.06233956729006235}\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: tensor(28.4915)\n",
      "Number of local model clusters after transfer = 254\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 2 after merge: {'accuracy': 0.9554264246339665, 'precision': 0.03326959847036329, 'recall': 0.8877551020408163, 'f1_score': 0.06413564319941024}\n",
      "--- End of Round 1 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9828833257259225, 'precision': 0.0721951219512195, 'recall': 0.7551020408163265, 'f1_score': 0.13178984861976847}, ROC AUC: 0.9502393106933263\n",
      "\n",
      "--- Communication Round 2 ---\n",
      "Client 1: {0: 132, 1: 132}\n",
      "Client 2: {0: 131, 1: 131}\n",
      "Client 3: {0: 131, 1: 131}\n",
      "Test Set: {0: 56864, 1: 98}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 57258 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 57750\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Number of local model clusters = 270\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 1\n",
      "Updated var_glo values: tensor(27.3472)\n",
      "Number of local model clusters = 270\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 2\n",
      "Updated var_glo values: tensor(27.7367)\n",
      "Number of local model clusters = 291\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 3\n",
      "Updated var_glo values: tensor(28.0274)\n",
      "Agreggated clusters after transfer = 478\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Aggregated Metrics: {'accuracy': 0.9866051051578245, 'precision': 0.10179640718562874, 'recall': 0.8673469387755102, 'f1_score': 0.18220793140407288}\n",
      "Federated clusters after merging = 285\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9889399950844423, 'precision': 0.11781609195402298, 'recall': 0.8367346938775511, 'f1_score': 0.2065491183879093}\n",
      "Test ROC AUC: 0.9560715218839364\n",
      "\n",
      "\n",
      "Returning updated model to client 1\n",
      "Updated var_glo values: tensor(27.8571)\n",
      "Number of local model clusters after transfer = 334\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 0 after merge: {'accuracy': 0.9968048874688389, 'precision': 0.3037383177570093, 'recall': 0.6632653061224489, 'f1_score': 0.41666666666666663}\n",
      "Returning updated model to client 2\n",
      "Updated var_glo values: tensor(28.0523)\n",
      "Number of local model clusters after transfer = 355\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 1 after merge: {'accuracy': 0.9969453319757031, 'precision': 0.3155339805825243, 'recall': 0.6632653061224489, 'f1_score': 0.4276315789473684}\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: tensor(28.1727)\n",
      "Number of local model clusters after transfer = 362\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 2 after merge: {'accuracy': 0.9954004424001967, 'precision': 0.22483221476510068, 'recall': 0.6836734693877551, 'f1_score': 0.33838383838383834}\n",
      "--- End of Round 2 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9828833257259225, 'precision': 0.0721951219512195, 'recall': 0.7551020408163265, 'f1_score': 0.13178984861976847}, ROC AUC: 0.9502393106933263\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9889399950844423, 'precision': 0.11781609195402298, 'recall': 0.8367346938775511, 'f1_score': 0.2065491183879093}, ROC AUC: 0.9560715218839364\n",
      "\n",
      "--- Communication Round 3 ---\n",
      "Client 1: {0: 132, 1: 132}\n",
      "Client 2: {0: 131, 1: 131}\n",
      "Client 3: {0: 131, 1: 131}\n",
      "Test Set: {0: 56864, 1: 98}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 57258 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 57750\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Number of local model clusters = 377\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 1\n",
      "Updated var_glo values: tensor(27.7524)\n",
      "Number of local model clusters = 382\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 2\n",
      "Updated var_glo values: tensor(27.8973)\n",
      "Number of local model clusters = 383\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 3\n",
      "Updated var_glo values: tensor(28.0357)\n",
      "Agreggated clusters after transfer = 642\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Aggregated Metrics: {'accuracy': 0.9936448860643938, 'precision': 0.18571428571428572, 'recall': 0.7959183673469388, 'f1_score': 0.30115830115830117}\n",
      "Federated clusters after merging = 279\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.994996664442962, 'precision': 0.2208955223880597, 'recall': 0.7551020408163265, 'f1_score': 0.3418013856812933}\n",
      "Test ROC AUC: 0.9059142544187062\n",
      "\n",
      "\n",
      "Returning updated model to client 1\n",
      "Updated var_glo values: tensor(27.9648)\n",
      "Number of local model clusters after transfer = 310\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 0 after merge: {'accuracy': 0.998121554720691, 'precision': 0.47096774193548385, 'recall': 0.7448979591836735, 'f1_score': 0.5770750988142292}\n",
      "Returning updated model to client 2\n",
      "Updated var_glo values: tensor(28.0373)\n",
      "Number of local model clusters after transfer = 358\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 1 after merge: {'accuracy': 0.9979459990871107, 'precision': 0.4370860927152318, 'recall': 0.673469387755102, 'f1_score': 0.5301204819277108}\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: tensor(28.1049)\n",
      "Number of local model clusters after transfer = 339\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 2 after merge: {'accuracy': 0.9979986657771848, 'precision': 0.44666666666666666, 'recall': 0.6836734693877551, 'f1_score': 0.5403225806451613}\n",
      "--- End of Round 3 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9828833257259225, 'precision': 0.0721951219512195, 'recall': 0.7551020408163265, 'f1_score': 0.13178984861976847}, ROC AUC: 0.9502393106933263\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9889399950844423, 'precision': 0.11781609195402298, 'recall': 0.8367346938775511, 'f1_score': 0.2065491183879093}, ROC AUC: 0.9560715218839364\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.994996664442962, 'precision': 0.2208955223880597, 'recall': 0.7551020408163265, 'f1_score': 0.3418013856812933}, ROC AUC: 0.9059142544187062\n",
      "\n",
      "--- Communication Round 4 ---\n",
      "Client 1: {0: 132, 1: 132}\n",
      "Client 2: {0: 131, 1: 131}\n",
      "Client 3: {0: 131, 1: 131}\n",
      "Test Set: {0: 56864, 1: 98}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 57258 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 57750\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Number of local model clusters = 356\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 1\n",
      "Updated var_glo values: tensor(27.9409)\n",
      "Number of local model clusters = 385\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 2\n",
      "Updated var_glo values: tensor(27.9919)\n",
      "Number of local model clusters = 356\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 3\n",
      "Updated var_glo values: tensor(28.0342)\n",
      "Agreggated clusters after transfer = 720\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Aggregated Metrics: {'accuracy': 0.9966468873986166, 'precision': 0.30864197530864196, 'recall': 0.7653061224489796, 'f1_score': 0.4398826979472141}\n",
      "Federated clusters after merging = 323\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9980688880306169, 'precision': 0.461038961038961, 'recall': 0.7244897959183674, 'f1_score': 0.5634920634920634}\n",
      "Test ROC AUC: 0.8848618759546587\n",
      "\n",
      "\n",
      "Returning updated model to client 1\n",
      "Updated var_glo values: tensor(28.0109)\n",
      "Number of local model clusters after transfer = 360\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 0 after merge: {'accuracy': 0.998156665847407, 'precision': 0.47619047619047616, 'recall': 0.7142857142857143, 'f1_score': 0.5714285714285714}\n",
      "Returning updated model to client 2\n",
      "Updated var_glo values: tensor(28.0364)\n",
      "Number of local model clusters after transfer = 380\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 1 after merge: {'accuracy': 0.9987886661282961, 'precision': 0.6283185840707964, 'recall': 0.7244897959183674, 'f1_score': 0.6729857819905214}\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: tensor(28.0554)\n",
      "Number of local model clusters after transfer = 377\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 2 after merge: {'accuracy': 0.998156665847407, 'precision': 0.47770700636942676, 'recall': 0.7653061224489796, 'f1_score': 0.588235294117647}\n",
      "--- End of Round 4 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9828833257259225, 'precision': 0.0721951219512195, 'recall': 0.7551020408163265, 'f1_score': 0.13178984861976847}, ROC AUC: 0.9502393106933263\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9889399950844423, 'precision': 0.11781609195402298, 'recall': 0.8367346938775511, 'f1_score': 0.2065491183879093}, ROC AUC: 0.9560715218839364\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.994996664442962, 'precision': 0.2208955223880597, 'recall': 0.7551020408163265, 'f1_score': 0.3418013856812933}, ROC AUC: 0.9059142544187062\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9980688880306169, 'precision': 0.461038961038961, 'recall': 0.7244897959183674, 'f1_score': 0.5634920634920634}, ROC AUC: 0.8848618759546587\n",
      "\n",
      "--- Communication Round 5 ---\n",
      "Client 1: {0: 132, 1: 132}\n",
      "Client 2: {0: 131, 1: 131}\n",
      "Client 3: {0: 131, 1: 131}\n",
      "Test Set: {0: 56864, 1: 98}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 57258 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 57750\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Number of local model clusters = 399\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 1\n",
      "Updated var_glo values: tensor(28.0047)\n",
      "Number of local model clusters = 400\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 2\n",
      "Updated var_glo values: tensor(28.0209)\n",
      "Number of local model clusters = 398\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 3\n",
      "Updated var_glo values: tensor(28.0339)\n",
      "Agreggated clusters after transfer = 972\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Aggregated Metrics: {'accuracy': 0.9981742214107651, 'precision': 0.4794520547945205, 'recall': 0.7142857142857143, 'f1_score': 0.5737704918032787}\n",
      "Federated clusters after merging = 452\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9983322214809873, 'precision': 0.5109489051094891, 'recall': 0.7142857142857143, 'f1_score': 0.5957446808510638}\n",
      "Test ROC AUC: 0.882690027333387\n",
      "\n",
      "\n",
      "Returning updated model to client 1\n",
      "Updated var_glo values: tensor(28.0266)\n",
      "Number of local model clusters after transfer = 369\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 0 after merge: {'accuracy': 0.9960675538078017, 'precision': 0.26492537313432835, 'recall': 0.7244897959183674, 'f1_score': 0.3879781420765027}\n",
      "Returning updated model to client 2\n",
      "Updated var_glo values: tensor(28.0347)\n",
      "Number of local model clusters after transfer = 388\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 1 after merge: {'accuracy': 0.9945051086689372, 'precision': 0.2086720867208672, 'recall': 0.7857142857142857, 'f1_score': 0.3297644539614561}\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: tensor(28.0405)\n",
      "Number of local model clusters after transfer = 381\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 2 after merge: {'accuracy': 0.9945402197956532, 'precision': 0.20498614958448755, 'recall': 0.7551020408163265, 'f1_score': 0.3224400871459695}\n",
      "--- End of Round 5 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9828833257259225, 'precision': 0.0721951219512195, 'recall': 0.7551020408163265, 'f1_score': 0.13178984861976847}, ROC AUC: 0.9502393106933263\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9889399950844423, 'precision': 0.11781609195402298, 'recall': 0.8367346938775511, 'f1_score': 0.2065491183879093}, ROC AUC: 0.9560715218839364\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.994996664442962, 'precision': 0.2208955223880597, 'recall': 0.7551020408163265, 'f1_score': 0.3418013856812933}, ROC AUC: 0.9059142544187062\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9980688880306169, 'precision': 0.461038961038961, 'recall': 0.7244897959183674, 'f1_score': 0.5634920634920634}, ROC AUC: 0.8848618759546587\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9983322214809873, 'precision': 0.5109489051094891, 'recall': 0.7142857142857143, 'f1_score': 0.5957446808510638}, ROC AUC: 0.882690027333387\n",
      "\n",
      "--- Communication Round 6 ---\n",
      "Client 1: {0: 132, 1: 132}\n",
      "Client 2: {0: 131, 1: 131}\n",
      "Client 3: {0: 131, 1: 131}\n",
      "Test Set: {0: 56864, 1: 98}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 57258 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 57750\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Number of local model clusters = 395\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 1\n",
      "Updated var_glo values: tensor(28.0266)\n",
      "Number of local model clusters = 400\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 2\n",
      "Updated var_glo values: tensor(28.0311)\n",
      "Number of local model clusters = 400\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 3\n",
      "Updated var_glo values: tensor(28.0346)\n",
      "Agreggated clusters after transfer = 1029\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Aggregated Metrics: {'accuracy': 0.9983848881710614, 'precision': 0.5230769230769231, 'recall': 0.6938775510204082, 'f1_score': 0.5964912280701755}\n",
      "Federated clusters after merging = 472\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9984726659878516, 'precision': 0.5462184873949579, 'recall': 0.6632653061224489, 'f1_score': 0.5990783410138247}\n",
      "Test ROC AUC: 0.8782086941416971\n",
      "\n",
      "\n",
      "Returning updated model to client 1\n",
      "Updated var_glo values: tensor(28.0326)\n",
      "Number of local model clusters after transfer = 363\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 0 after merge: {'accuracy': 0.9939959973315544, 'precision': 0.1806282722513089, 'recall': 0.7040816326530612, 'f1_score': 0.2875}\n",
      "Returning updated model to client 2\n",
      "Updated var_glo values: tensor(28.0348)\n",
      "Number of local model clusters after transfer = 387\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 1 after merge: {'accuracy': 0.9895544398019732, 'precision': 0.12061068702290076, 'recall': 0.8061224489795918, 'f1_score': 0.20982735723771578}\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: tensor(28.0364)\n",
      "Number of local model clusters after transfer = 384\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 2 after merge: {'accuracy': 0.9920648853621713, 'precision': 0.1515748031496063, 'recall': 0.7857142857142857, 'f1_score': 0.25412541254125415}\n",
      "--- End of Round 6 ---\n",
      "\n",
      "Round 1: Metrics: {'accuracy': 0.9828833257259225, 'precision': 0.0721951219512195, 'recall': 0.7551020408163265, 'f1_score': 0.13178984861976847}, ROC AUC: 0.9502393106933263\n",
      "\n",
      "Round 2: Metrics: {'accuracy': 0.9889399950844423, 'precision': 0.11781609195402298, 'recall': 0.8367346938775511, 'f1_score': 0.2065491183879093}, ROC AUC: 0.9560715218839364\n",
      "\n",
      "Round 3: Metrics: {'accuracy': 0.994996664442962, 'precision': 0.2208955223880597, 'recall': 0.7551020408163265, 'f1_score': 0.3418013856812933}, ROC AUC: 0.9059142544187062\n",
      "\n",
      "Round 4: Metrics: {'accuracy': 0.9980688880306169, 'precision': 0.461038961038961, 'recall': 0.7244897959183674, 'f1_score': 0.5634920634920634}, ROC AUC: 0.8848618759546587\n",
      "\n",
      "Round 5: Metrics: {'accuracy': 0.9983322214809873, 'precision': 0.5109489051094891, 'recall': 0.7142857142857143, 'f1_score': 0.5957446808510638}, ROC AUC: 0.882690027333387\n",
      "\n",
      "Round 6: Metrics: {'accuracy': 0.9984726659878516, 'precision': 0.5462184873949579, 'recall': 0.6632653061224489, 'f1_score': 0.5990783410138247}, ROC AUC: 0.8782086941416971\n",
      "\n",
      "--- Communication Round 7 ---\n",
      "Client 1: {0: 132, 1: 132}\n",
      "Client 2: {0: 131, 1: 131}\n",
      "Client 3: {0: 131, 1: 131}\n",
      "Test Set: {0: 56864, 1: 98}\n",
      "\n",
      "Combined Number of Samples per Class:\n",
      "Class 0: 57258 samples\n",
      "Class 1: 492 samples\n",
      "\n",
      "Total Number of Samples Across All Datasets: 57750\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Debugging has been disabled.\n",
      "Evolving has been enabled.\n",
      "Number of local model clusters = 383\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 1\n",
      "Updated var_glo values: tensor(28.0322)\n",
      "Number of local model clusters = 400\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 2\n",
      "Updated var_glo values: tensor(28.0335)\n",
      "Number of local model clusters = 400\n",
      "Evolving has been disabled.\n",
      "Train Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n",
      "Updating agreggated model with client 3\n",
      "Updated var_glo values: tensor(28.0346)\n",
      "Agreggated clusters after transfer = 1021\n",
      "\n",
      "\n",
      "Evolving has been disabled.\n",
      "Aggregated Metrics: {'accuracy': 0.9979811102138267, 'precision': 0.445859872611465, 'recall': 0.7142857142857143, 'f1_score': 0.5490196078431373}\n",
      "Federated clusters after merging = 485\n",
      "Evolving has been disabled.\n",
      "Test Metrics: {'accuracy': 0.9978231101436045, 'precision': 0.4166666666666667, 'recall': 0.6632653061224489, 'f1_score': 0.5118110236220472}\n",
      "Test ROC AUC: 0.8661557687227959\n",
      "\n",
      "\n",
      "Returning updated model to client 1\n",
      "Updated var_glo values: tensor(28.0340)\n",
      "Number of local model clusters after transfer = 373\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 0 after merge: {'accuracy': 0.9926617745163442, 'precision': 0.15065502183406113, 'recall': 0.7040816326530612, 'f1_score': 0.24820143884892087}\n",
      "Returning updated model to client 2\n",
      "Updated var_glo values: tensor(28.0346)\n",
      "Number of local model clusters after transfer = 393\n",
      "Evolving has been disabled.\n",
      "Test Metrics client 1 after merge: {'accuracy': 0.9948562199360977, 'precision': 0.21407624633431085, 'recall': 0.7448979591836735, 'f1_score': 0.3325740318906606}\n",
      "Returning updated model to client 3\n",
      "Updated var_glo values: tensor(28.0351)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Assuming local_models, client_train, federated_model, and test_data are already defined\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Number of communication rounds\u001b[39;00m\n\u001b[0;32m     44\u001b[0m num_rounds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m---> 46\u001b[0m experiments \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mdata_config_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_config_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfederated_model_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfederated_model_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mlocal_model_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlocal_model_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproportion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 47\u001b[0m, in \u001b[0;36mrun_experiments\u001b[1;34m(data, client_counts, data_config_indices, federated_model_params, local_model_params, num_rounds, proportion, profiler)\u001b[0m\n\u001b[0;32m     45\u001b[0m             yappi\u001b[38;5;241m.\u001b[39mget_func_stats()\u001b[38;5;241m.\u001b[39mprint_all()\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m             metrics \u001b[38;5;241m=\u001b[39m \u001b[43mrun_individual_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfederated_model_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfederated_model_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mlocal_model_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_model_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_clients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mclient_raw_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_raw_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mbalance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbalance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m         experiments\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_clients_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_clients\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_sampling_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_config_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, metrics))\n\u001b[0;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(experiments, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_metrics.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 87\u001b[0m, in \u001b[0;36mrun_individual_experiment\u001b[1;34m(federated_model_params, local_model_params, num_clients, num_rounds, client_raw_train, test_data, balance, test_clients)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning updated model to client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m local_models[client_idx]\u001b[38;5;241m.\u001b[39mfederal_agent\u001b[38;5;241m.\u001b[39mmerge_model_privately(federated_model, federated_model\u001b[38;5;241m.\u001b[39mkappa_n, pred_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m \u001b[43mlocal_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfederal_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfederated_merging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of local model clusters after transfer = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(local_models[client_idx]\u001b[38;5;241m.\u001b[39mn[\u001b[38;5;241m0\u001b[39m:local_models[client_idx]\u001b[38;5;241m.\u001b[39mc]\u001b[38;5;241m>\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_clients:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Calculate and collect metrics for each client model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mihao\\OneDrive - Univerza v Ljubljani\\Doktorski_studij\\Delo\\eGAUSSp_Python\\model\\federated_operations.py:46\u001b[0m, in \u001b[0;36mFederalOps.federated_merging\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mGamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmathematician\u001b[38;5;241m.\u001b[39mcompute_activation(center)  \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#Use the merging mechanism \u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerging_mech\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerging_mechanism\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m#Remove small clusters \u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmatching_clusters \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mcluster_labels[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mc][:, label])[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mihao\\OneDrive - Univerza v Ljubljani\\Doktorski_studij\\Delo\\eGAUSSp_Python\\model\\merging_mechanism.py:269\u001b[0m, in \u001b[0;36mMergingMechanism.merging_mechanism\u001b[1;34m(self, max_iterations)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m#Compute the volume of the combined clusters\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_volume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# Compute merging condition kappa\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_kappa()\n",
      "File \u001b[1;32mc:\\Users\\mihao\\OneDrive - Univerza v Ljubljani\\Doktorski_studij\\Delo\\eGAUSSp_Python\\model\\merging_mechanism.py:151\u001b[0m, in \u001b[0;36mMergingMechanism.compute_volume\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m Sigma \u001b[38;5;241m=\u001b[39m Sigma\u001b[38;5;241m/\u001b[39m(n_matrix[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Compute log-determinant for numerical stability\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Compute log-determinant for numerical stability\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m#L = torch.linalg.cholesky(Sigma)\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m#det_matrix = torch.prod(torch.diag(L))**2\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m det_matrix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslogdet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSigma\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# [1] is the log determinant\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Vectorized computation of volume V for upper triangle\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV \u001b[38;5;241m=\u001b[39m det_matrix\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mfeature_dim)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "\n",
    "    # Example usage\n",
    "    best_setting, best_f1_score, all_experiments_metrics = run_parameterized_experiments(data, client_counts, data_config_indices, 30, profiler=False)\n",
    "    print(\"Best Setting:\", best_setting)\n",
    "    print(\"Best F1 Score:\", best_f1_score)\n",
    "\n",
    "    # Save the best setting and all experiments' metrics\n",
    "    torch.save({\n",
    "        \"best_setting\": best_setting,\n",
    "        \"best_f1_score\": best_f1_score,\n",
    "        \"experiments_metrics\": all_experiments_metrics\n",
    "    }, 'experiment_results.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the model parameters with the best setting\n",
    "federated_model_params.update({\n",
    "    \"num_sigma\": best_setting[0],\n",
    "    \"kappa_join\": best_setting[1],\n",
    "    \"N_r\": best_setting[2]\n",
    "})\n",
    "\n",
    "local_model_params.update({\n",
    "    \"num_sigma\": best_setting[0],\n",
    "    \"kappa_join\": best_setting[1],\n",
    "    \"N_r\": best_setting[2]\n",
    "})\n",
    "\n",
    "# Set the number of rounds and proportion with the best setting\n",
    "num_rounds = 30\n",
    "proportion = best_setting[3]\n",
    "\n",
    "# Run the experiments with the best setting for 30 rounds\n",
    "experiments = run_experiments(\n",
    "    data=data, \n",
    "    client_counts=client_counts,\n",
    "    data_config_indices=data_config_indices, \n",
    "    federated_model_params=federated_model_params, \n",
    "    local_model_params=local_model_params, \n",
    "    num_rounds=num_rounds, \n",
    "    proportion=proportion, \n",
    "    profiler=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = torch.load('experiment_metrics.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_metrics = []\n",
    "figs_clusters = []\n",
    "experiment_name = []\n",
    "for exp_num, (name, metrics) in enumerate(experiments):\n",
    "    rounds = [m['round'] for m in metrics]\n",
    "\n",
    "    # Plot and collect figures\n",
    "    legend = True if exp_num == 0 else False\n",
    "    experiment_name.append(name)\n",
    "    figs_metrics.append(plot_metric_data(metrics, ['f1_score', 'precision', 'recall'], rounds, f'Experiment {exp_num+1} - Metrics', legend=legend))\n",
    "    figs_clusters.append(plot_cluster_data(metrics, rounds, legend=legend))\n",
    "\n",
    "# Save figures from fig_metrics\n",
    "for i, figure in enumerate(figs_metrics):\n",
    "    save_path = f\".Images/credit_fraud_metrics_{experiment_name[i]}.pdf\"\n",
    "    save_figure(figure, save_path, \"pdf\")\n",
    "\n",
    "# Save figures from fig_clusters\n",
    "for i, figure in enumerate(figs_clusters):\n",
    "    save_path = f\".Images/credit_fraud_clusters_{experiment_name[i]}.pdf\"\n",
    "    save_figure(figure, save_path, \"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for client_idx, client_model in enumerate(local_models):\n",
    "        print(f\"Merging client {client_idx + 1}\")\n",
    "        #print(f\"Number of client {client_idx + 1} clusters before merging = {torch.sum(client_model.n[:client_model.c]>client_model.kappa_n)}\")\n",
    "        #client_model.federal_agent.federated_merging() \n",
    "        print(f\"Number of client {client_idx + 1} after merging = {torch.sum(client_model.n[:client_model.c]>client_model.kappa_n)}\")\n",
    "        federated_model.federal_agent.merge_model_privately(client_model, client_model.kappa_n)\n",
    "\n",
    "print(f\"Number of clusters after transfer = {federated_model.c}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "federated_model.federal_agent.federated_merging()\n",
    "federated_model.removal_mech.removal_mechanism()\n",
    "print(f\"Number of clusters after merging = {federated_model.c}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "print(f\"\\nTesting federated model\")   \n",
    "\n",
    "all_scores, pred_max, _ = test_model(federated_model, test_data)\n",
    "metrics = calculate_metrics(pred_max, test_data, \"binary\")\n",
    "print(f\"Test Metrics: {metrics}\")\n",
    "roc_auc = calculate_roc_auc(all_scores, test_data)\n",
    "print(f\"Test ROC AUC: {roc_auc}\")\n",
    "\n",
    "plot_confusion_matrix(pred_max, test_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Confusion matrix values\n",
    "tn = 135\n",
    "fn = 10\n",
    "tp = 132\n",
    "fp = 19\n",
    "\n",
    "# Creating the confusion matrix\n",
    "y_true = [0]*tn + [1]*fn + [1]*tp + [0]*fp  # 0 for negative class, 1 for positive class\n",
    "y_pred = [0]*(tn+fn) + [1]*(fp+tp)  # Predictions\n",
    "\n",
    "# Calculating metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(accuracy, precision, recall, f1)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
