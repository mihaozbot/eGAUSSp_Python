{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import importlib\n",
    "from utils.utils_dataset import prepare_k_fold_non_iid_dataset, plot_dataset_split, display_dataset_split\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "from utils.utils_train import train_supervised, test_model\n",
    "from utils.utils_plots import plot_first_feature_horizontal, save_figure\n",
    "from utils.utils_metrics import calculate_metrics_statistics, calculate_cluster_stats, calculate_metrics, plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.1.2\n",
      "CUDA Version: None\n",
      "CUDA not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "from model.eGauss_plus import eGAUSSp\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "\n",
    "# Check if CUDA is available\n",
    "#if torch.cuda.is_available():\n",
    "    #device = torch.device(\"cuda\")\n",
    "    #print(\"CUDA is available. Using GPU.\")\n",
    "#else:\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"CUDA not available. Using CPU.\")\n",
    "\n",
    "feature_dim = 4\n",
    "num_classes = 3\n",
    "\n",
    "# Model parameters\n",
    "local_model_params = {\n",
    "    \"feature_dim\": feature_dim,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 2,\n",
    "    \"kappa_join\": 0.5,\n",
    "    \"S_0\": 1e-8,\n",
    "    \"N_r\": 8,\n",
    "    \"c_max\": 1000,\n",
    "    \"device\": device\n",
    "}\n",
    "federated_model_params = {\n",
    "    \"feature_dim\": feature_dim,\n",
    "    \"num_classes\": num_classes,\n",
    "    \"kappa_n\": 1,\n",
    "    \"num_sigma\": 5,\n",
    "    \"kappa_join\": 5,\n",
    "    \"S_0\": 1e-8,\n",
    "    \"N_r\": 8,\n",
    "    \"c_max\": 1000,\n",
    "    \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "num_clients = 4\n",
    "num_splits = 5\n",
    "num_repetitions = 10\n",
    "\n",
    "# Re-inserting the repetition of the experiment 10 times\n",
    "experiment_results = []\n",
    "for experiment in range(num_repetitions):\n",
    "    kf = KFold(n_splits=num_splits, shuffle=True, random_state=None)\n",
    "\n",
    "    # Initialize arrays to track samples per class for each client in each fold\n",
    "    samples_per_class_per_client = np.zeros((num_clients, local_model_params[\"num_classes\"], num_splits))\n",
    "\n",
    "    # Main loop for k-fold cross-validation\n",
    "    all_client_metrics = [[] for _ in range(num_clients)]\n",
    "    all_client_clusters = [[] for _ in range(num_clients)]\n",
    "\n",
    "    all_federated_metrics = []\n",
    "    all_federated_clusters = []\n",
    "\n",
    "    for i_fold, (train_index, test_index) in enumerate(kf.split(iris.data)):\n",
    "        # Split the data\n",
    "        train_data, test_data, all_data = prepare_k_fold_non_iid_dataset(X, y, train_index, test_index, num_clients)\n",
    "\n",
    "        # Create the models\n",
    "        local_models = [eGAUSSp(**local_model_params) for _ in range(num_clients)]\n",
    "        federated_model = eGAUSSp(**federated_model_params)\n",
    "\n",
    "        # Train and test the models\n",
    "        for client_idx, client_model in enumerate(local_models):\n",
    "            # Count the number of samples per class for this client in this fold\n",
    "            for class_idx in range(client_model.num_classes):\n",
    "                class_samples = torch.sum((train_data[client_idx][1] == class_idx).float(), dim=0)\n",
    "                samples_per_class_per_client[client_idx, class_idx, i_fold] = class_samples\n",
    "\n",
    "            # Supervised clustering\n",
    "            train_supervised(client_model, train_data[client_idx])\n",
    "\n",
    "            # Test the local models\n",
    "            _, pred, _ = test_model(client_model, test_data)\n",
    "            metrics = calculate_metrics(pred, test_data, \"weighted\")\n",
    "            all_client_metrics[client_idx].append(metrics)\n",
    "\n",
    "            # Save the number of clusters\n",
    "            num_client_clusters = torch.sum(client_model.n[:client_model.c] > 1)\n",
    "            all_client_clusters[client_idx].append(num_client_clusters)\n",
    "\n",
    "        # Aggregate local models\n",
    "        for client_model in local_models:\n",
    "            federated_model.federal_agent.merge_model_privately(client_model, federated_model.kappa_n)\n",
    "\n",
    "        federated_model.federal_agent.federated_merging()\n",
    "\n",
    "        num_federated_clusters = torch.sum(federated_model.n[:federated_model.c] > 0)\n",
    "        all_federated_clusters.append(num_federated_clusters)\n",
    "\n",
    "        # Test the federated model\n",
    "        _, pred_fed, _ = test_model(federated_model, test_data)\n",
    "        federated_metrics = calculate_metrics(pred_fed, test_data, \"weighted\")\n",
    "        all_federated_metrics.append(federated_metrics)\n",
    "\n",
    "    # Store results of each experiment\n",
    "    experiment_results.append({\n",
    "        \"client_metrics\": all_client_metrics,\n",
    "        \"client_clusters\": all_client_clusters,\n",
    "        \"federated_metrics\": all_federated_metrics,\n",
    "        \"federated_clusters\": all_federated_clusters,\n",
    "        \"samples_per_class_per_client\": samples_per_class_per_client\n",
    "    })\n",
    "    \n",
    "# Displaying the result of the first experiment for brevity\n",
    "experiment_results[0]  # Replace with desired processing or analysis of experiment results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize variables to store aggregated data\n",
    "agg_client_metrics = [{} for _ in range(num_clients)]\n",
    "agg_federated_metrics = {}\n",
    "agg_client_clusters = [[] for _ in range(num_clients)]\n",
    "agg_federated_clusters = []\n",
    "\n",
    "# Process each experiment\n",
    "for result in experiment_results:\n",
    "    for client_idx, client_metrics in enumerate(result['client_metrics']):\n",
    "        for metric in client_metrics[0].keys():\n",
    "            if metric not in agg_client_metrics[client_idx]:\n",
    "                agg_client_metrics[client_idx][metric] = []\n",
    "            agg_client_metrics[client_idx][metric].extend([m[metric] for m in client_metrics])\n",
    "\n",
    "    for metric in result['federated_metrics'][0].keys():\n",
    "        if metric not in agg_federated_metrics:\n",
    "            agg_federated_metrics[metric] = []\n",
    "        agg_federated_metrics[metric].extend([m[metric] for m in result['federated_metrics']])\n",
    "\n",
    "    for client_idx, client_clusters in enumerate(result['client_clusters']):\n",
    "        agg_client_clusters[client_idx].extend(client_clusters)\n",
    "\n",
    "    agg_federated_clusters.extend(result['federated_clusters'])\n",
    "\n",
    "# Calculate averages and standard deviations\n",
    "for client_metrics in agg_client_metrics:\n",
    "    for metric, values in client_metrics.items():\n",
    "        mean = np.mean(values)\n",
    "        std = np.std(values, ddof=1)\n",
    "        client_metrics[metric] = (mean, std)\n",
    "\n",
    "for metric, values in agg_federated_metrics.items():\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values, ddof=1)\n",
    "    agg_federated_metrics[metric] = (mean, std)\n",
    "\n",
    "# Example of printing aggregated metrics for the first client\n",
    "print(\"Aggregated Metrics for Client 1:\")\n",
    "for metric, (mean, std) in agg_client_metrics[0].items():\n",
    "    print(f\"{metric}: {mean:.2f} ± {std:.2f}\")\n",
    "\n",
    "agg_samples = np.zeros((num_clients, num_classes, num_splits))\n",
    "\n",
    "# Aggregate data from each experiment\n",
    "for result in experiment_results:\n",
    "    samples_per_class_per_client = result['samples_per_class_per_client']\n",
    "    agg_samples += samples_per_class_per_client\n",
    "\n",
    "# Compute the average across all repetitions (and folds if required)\n",
    "avg_samples = agg_samples / len(experiment_results)\n",
    "\n",
    "# Calculate the average for each client and class across folds\n",
    "avg_samples_per_class_per_client = avg_samples.mean(axis=2)\n",
    "\n",
    "# Print the results\n",
    "for client_idx in range(num_clients):\n",
    "    print(f\"Client {client_idx + 1}:\")\n",
    "    for class_idx in range(num_classes):\n",
    "        avg_samples = avg_samples_per_class_per_client[client_idx, class_idx]\n",
    "        print(f\"  Class {class_idx}: {avg_samples:.2f} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LaTeX table for the paper\n",
    "# Start the LaTeX table code\n",
    "latex_table = r\"\"\"\\begin{table}[ht]\n",
    "\\centering\n",
    "\\setlength{\\tabcolsep}{2pt}\n",
    "\\scriptsize\n",
    "\\caption{Performance metrics and average number of clusters on the Iris dataset.}\n",
    "\\label{tab:performance_clusters}\n",
    "\\begin{tabular}{lcccccc}\n",
    "\\toprule\n",
    "\\textbf{Metric} & \\textbf{Client 1} & \\textbf{Client 2} & \\textbf{Client 3} & \\textbf{Client 4} & \\textbf{Federated} \\\\\n",
    "\"\"\"\n",
    "\n",
    "# Add the header for average samples per class\n",
    "latex_table += r\"Average Samples &\"\n",
    "\n",
    "# Add the average samples per class for each client\n",
    "samples_row = \"\"\n",
    "for samples in avg_samples_per_class_per_client:\n",
    "    samples_row += \" & \" + \"/\".join([f\"{x:.1f}\" for x in samples])\n",
    "latex_table += samples_row + \" \\\\\\\\\" + \"\\n\"\n",
    "\n",
    "latex_table += r\"\\midrule\" + \"\\n\"\n",
    "\n",
    "\n",
    "# Add rows for each metric\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "metric_names = ['Accuracy (\\%)', 'Precision (\\%)', 'Recall (\\%)', 'F1 Score (\\%)']\n",
    "for i, metric in enumerate(metrics):\n",
    "    row = metric_names[i] + r' $\\uparrow$'\n",
    "    for client_metrics in agg_client_metrics:\n",
    "        mean, std = client_metrics[metric]\n",
    "        row += f' & {mean * 100:.1f} ± {std * 100:.1f}'\n",
    "    mean, std = agg_federated_metrics[metric]\n",
    "    row += r' & \\bf' + f'{{{mean * 100:.1f} ± {std * 100:.1f}}}'\n",
    "    latex_table += row + r' \\\\' + '\\n'\n",
    "\n",
    "# Add row for clusters\n",
    "cluster_row = r'\\#Clusters $\\downarrow$'\n",
    "for client_clusters in agg_client_clusters:\n",
    "    avg_clusters = np.mean(client_clusters)\n",
    "    std_clusters = np.std(client_clusters, ddof=1)\n",
    "    cluster_row += f' & {avg_clusters:.1f} ± {std_clusters:.1f}'\n",
    "\n",
    "# Assuming agg_federated_clusters is a list of cluster counts for the federated model\n",
    "avg_fed_clusters = np.mean(agg_federated_clusters)\n",
    "std_fed_clusters = np.std(agg_federated_clusters, ddof=1)\n",
    "cluster_row += r' & \\bf' + f'{{{avg_fed_clusters:.1f} ± {std_fed_clusters:.1f}}}'\n",
    "\n",
    "latex_table += cluster_row + r' \\\\' + '\\n'\n",
    "\n",
    "# End the LaTeX table code\n",
    "latex_table += r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "# Print the complete LaTeX table\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aditional plots of the data\n",
    "display_dataset_split(train_data, test_data)\n",
    "fig = plot_dataset_split(train_data, test_data)\n",
    "save_figure(fig, \"Images/iris_data_distribution.svg\",\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of the last local model\n",
    "fig = plot_first_feature_horizontal(train_data[client_idx], model=client_model, num_sigma=2, N_max=1, title=\"\",format='%d', legend = True, data_name = \"Class\")  \n",
    "save_figure(fig, \"Images/iris_local_model.svg\", \"svg\")\n",
    "save_figure(fig, \"Images/iris_local_model.pdf\",\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of the last federated model\n",
    "fig = plot_first_feature_horizontal(test_data, model=federated_model, num_sigma=2, N_max=0, title=\"\", format='%d')   \n",
    "print(f\"Number of clusters after merging = {federated_model.c}\")\n",
    "save_figure(fig, \"Images/iris_federated_merged.svg\",\"svg\")\n",
    "save_figure(fig, \"Images/iris_federated_merged.pdf\",\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(pred_fed, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
